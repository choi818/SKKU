{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice5. Keras-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7639170295197750862\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6440340685\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7974773985356469065\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess= tf.Session(config=config)\n",
    "\n",
    "import sys\n",
    "from tensorflow.python.client import device_lib\n",
    "print (device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. reuters dataset 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "# cut texts after this number of words (among top max_features most common words), 바꾸지 마세요!\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
    "                                                         num_words=max_features,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data shape 확인\n",
    "- x_train, x_test의 형태를 꼭 확인할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape :  (8982,) \ty_train.shape :  (8982,)\n",
      "x_test.shape :  (2246,) \ty_test.shape :  (2246,)\n",
      "\n",
      "len(x_train[0]) :  87 \tlen(x_test[0]) :  145\n",
      "len(x_train[-1]) :  105 \tlen(x_test[-1]) :  272\n"
     ]
    }
   ],
   "source": [
    "print ('x_train.shape : ', x_train.shape,'\\ty_train.shape : ',  y_train.shape)\n",
    "print ('x_test.shape : ', x_test.shape,'\\ty_test.shape : ',  y_test.shape)\n",
    "print ()\n",
    "print ('len(x_train[0]) : ', len(x_train[0]),'\\tlen(x_test[0]) : ', len(x_test[0]))\n",
    "print ('len(x_train[-1]) : ', len(x_train[-1]),'\\tlen(x_test[-1]) : ', len(x_test[-1]))\n",
    "# print()\n",
    "# print(x_train[1])\n",
    "# print()\n",
    "# print(y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. a list of sequences를 2D Numpy array로 변환\n",
    "- 참고 : https://keras.io/preprocessing/sequence/#pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length for embedding is 120\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "################################### 바꿔가면서 해보세요 ################################\n",
    "\n",
    "max_sentence_length = 120\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_sentence_length)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_sentence_length)\n",
    "\n",
    "print ('max sentence length for embedding is %d' % (max_sentence_length))\n",
    "# print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification을 위한 cetegorical label 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_label :  46\n",
      "x_train.shape \t: (8982, 120)\n",
      "y_train_onehot.shape : (8982, 46)\n",
      "x_test.shape \t: (2246, 120)\n",
      "y_test_onehot.shape : (2246, 46)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "output_shape = np.max(y_train) + 1\n",
    "\n",
    "print (\"max_label : \", output_shape)\n",
    "\n",
    "y_train_onehot=np_utils.to_categorical(y_train,output_shape)\n",
    "y_test_onehot=np_utils.to_categorical(y_test,output_shape)\n",
    "\n",
    "print ('x_train.shape \\t: ' + str(x_train.shape))\n",
    "print ('y_train_onehot.shape : ' + str(y_train_onehot.shape))\n",
    "print ('x_test.shape \\t: ' + str(x_test.shape))\n",
    "print ('y_test_onehot.shape : ' + str(y_test_onehot.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embedding vector length 설정\n",
    "- Embedding layer : https://keras.io/layers/embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding vector size is 32\n"
     ]
    }
   ],
   "source": [
    "################################### 바꿔가면서 해보세요 ################################\n",
    "\n",
    "embedding_vecor_length = 32    \n",
    "\n",
    "###################################################################################\n",
    "print ('embedding vector size is %d'% (embedding_vecor_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 만들기\n",
    "- Keras Documentation : https://keras.io\n",
    "- Embedding layer : https://keras.io/layers/embeddings/\n",
    "- Recurrent layer : https://keras.io/layers/recurrent/\n",
    "- Convolution layer : https://keras.io/layers/convolutional/\n",
    "- Drop out : https://keras.io/layers/core/#dropout\n",
    "- Sequence classification with LSTM : https://keras.io/getting-started/sequential-model-guide/#sequence-classification-with-lstm\n",
    "- Documentation 참고하면서 다양한 형태로 모델을 만들어보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Dropout, Input\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "layer = input_layer\n",
    "\n",
    "################################### Documentation 참고해서 레이어를 바꿔보세요 ################################\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import MaxPooling1D\n",
    "\n",
    "layer = Sequential()(layer)\n",
    "layer = Embedding(max_features, 32, embeddings_initializer='uniform')(layer)\n",
    "layer = Dropout(0.2)(layer)\n",
    "layer = Conv1D(256, 3, padding='valid', activation='relu', strides=1)(layer)\n",
    "layer = GlobalMaxPooling1D()(layer)\n",
    "layer = Dense(128, activation='relu')(layer)\n",
    "# layer = LSTM(128, dropout=0.2, recurrent_dropout=0.2)(layer)\n",
    "layer = Dropout(0.2)(layer)\n",
    "# layer = Dense(64, activation='relu')(layer)\n",
    "\n",
    "# layer = GRU(64, return_sequences=True)(layer)\n",
    "# layer = GRU(64, return_sequences=True)(layer)\n",
    "# layer = GRU(128, dropout=0.2, recurrent_dropout=0.2)(layer)\n",
    "# layer = LSTM(128)(layer)\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "layer = Dense(output_shape, activation='softmax')(layer)\n",
    "\n",
    "output_layer = layer\n",
    "model = Model(inputs=[input_layer], outputs=[output_layer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer 설정, 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, RMSprop\n",
    "################################ 바꿔가면서 해보세요 ######################################\n",
    "rmsprop = Adam()\n",
    "######################################################################################\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary() 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "sequential_18 (Sequential)   (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "embedding_21 (Embedding)     (None, 120, 32)           160000    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 120, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 118, 256)          24832     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_9 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 46)                5934      \n",
      "=================================================================\n",
      "Total params: 223,662\n",
      "Trainable params: 223,662\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 visualization (선택)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.image as mpimg\n",
    "# from keras.utils import plot_model\n",
    "# import matplotlib.pyplot as plt\n",
    "# plot_model(model,'model_image.png', show_layer_names=False, show_shapes=True)\n",
    "# model_img=mpimg.imread('model_image.png')\n",
    "# plt.figure(figsize=[10,50])\n",
    "# plt.imshow(model_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/10\n",
      "2784/8982 [========>.....................] - ETA: 4s - loss: 2.5681 - acc: 0.3660"
     ]
    }
   ],
   "source": [
    "################################ 바꿔가면서 해보세요 ######################################\n",
    "num_epochs = 10\n",
    "mini_batch_size = 32\n",
    "######################################################################################\n",
    "history = model.fit(x_train, y_train_onehot,validation_data=[x_test, y_test_onehot], epochs=num_epochs, batch_size=mini_batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission :  Test Accuray 75% 이상 달성하기\n",
    "- 바꿀 수 있는 것 : max_sentence_length, embedding_vecor_length, num_epochs, mini_batch_size, Optimizer, 모델 구조\n",
    "- 위 요소들을 바꿔보면서 각각의 요소와 최종 결과의 관계를 한번 파악해보세요. (Overfitting vs Underfitting)\n",
    "- 달성한 Accuracy가 보이게 6. Visualization 까지 실행된 코드를 제출해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-618bbfab2ef2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#plot training graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#plot training graph\n",
    "plt.clf()\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.grid(True)\n",
    "plt.yticks(np.arange(0, max(max(history.history['loss']),max(history.history['val_loss'])), 0.1))\n",
    "plt.xticks(np.arange(0, num_epochs, 2))\n",
    "plt.ylim([0.0, max(max(history.history['loss']), max(history.history['val_loss']))])\n",
    "plt.xlim([0, num_epochs])\n",
    "\n",
    "plt.plot(history.history['loss'][:], lw=2, label='Training Loss')\n",
    "plt.plot(history.history['acc'][:], lw=2, label='Training Acc')\n",
    "plt.plot(history.history['val_loss'][:], lw=2, label='Test Loss')\n",
    "plt.plot(history.history['val_acc'][:], lw=2, label='Test Acc')\n",
    "\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training Loss','Training Acc', 'Test Loss','Test Acc'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "print ('Best accuray : ', round(np.max(np.array(history.history['val_acc'])),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
